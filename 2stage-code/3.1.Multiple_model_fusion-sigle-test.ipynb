{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用多模型融合\n",
    "\n",
    "1 用训练图像分别导出各finetune好了的模型特征，以及对应label\n",
    "\n",
    "2 构建分类器，并训练，保存权重\n",
    "\n",
    "3 用test图像导出特征，输入分类器预测\n",
    "\n",
    "4 输出预测结果到csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 导出特征和label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\XX\\Anaconda2\\envs\\keras\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import *\n",
    "\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4708 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n",
      "295/295 [==============================] - 77s 260ms/step\n",
      "40/40 [==============================] - 12s 290ms/step\n",
      "model InceptionV3\n",
      "(4708, 2048)\n",
      "(640, 2048)\n",
      "(4708,)\n",
      "model InceptionV3\n",
      "(4708, 2048)\n",
      "(624, 2048)\n",
      "(4708,)\n",
      "[0 0 0 ... 1 1 1]\n",
      "#\n",
      "Found 4708 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n",
      "295/295 [==============================] - 116s 393ms/step\n",
      "40/40 [==============================] - 16s 403ms/step\n",
      "model Xception\n",
      "(4708, 2048)\n",
      "(640, 2048)\n",
      "(4708,)\n",
      "model Xception\n",
      "(4708, 2048)\n",
      "(624, 2048)\n",
      "(4708,)\n",
      "[0 0 0 ... 1 1 1]\n",
      "#\n"
     ]
    }
   ],
   "source": [
    "def write_gap(MODEL, image_size, lambda_func=None, weights_file=None, train_imgs_path=None, test_imgs_path=None, model_name=None):\n",
    "    width = image_size[0]\n",
    "    height = image_size[1]\n",
    "    input_tensor = Input((height, width, 3))\n",
    "    x = input_tensor\n",
    "    if lambda_func:\n",
    "        x = Lambda(lambda_func)(x)\n",
    "    \n",
    "    # build a train liked network, to reload weights\n",
    "    load_base_model = MODEL(input_tensor=x, weights=None, include_top=False)\n",
    "    load_m_out = load_base_model.output\n",
    "    load_p_out = GlobalAveragePooling2D()(load_m_out)\n",
    "    load_p_out = Dropout(0.5)(load_p_out)\n",
    "    load_predictions = Dense(2, activation='softmax')(load_p_out)\n",
    "    load_model = Model(inputs=load_base_model.input, outputs=load_predictions)\n",
    "    load_model.load_weights(weights_file)\n",
    "    \n",
    "    \n",
    "    model = Model(load_model.input, load_p_out)\n",
    "    \n",
    "    \n",
    "    gen = ImageDataGenerator()\n",
    "    train_generator = gen.flow_from_directory(train_imgs_path, image_size, shuffle=False, class_mode=\"categorical\",\n",
    "                                              batch_size=16)\n",
    "    test_generator = gen.flow_from_directory(test_imgs_path, image_size, shuffle=False,\n",
    "                                             batch_size=16, class_mode=None)\n",
    "    \n",
    "    train_img_nums = train_generator.samples\n",
    "    test_img_nums = test_generator.samples\n",
    "    \n",
    "    train = model.predict_generator(train_generator, (train_img_nums//16) + 1, verbose=1)\n",
    "    test = model.predict_generator(test_generator, (test_img_nums//16) + 1, verbose=1)\n",
    "\n",
    "    print(\"model %s\"%(model_name))\n",
    "    print(train.shape)\n",
    "    print(test.shape)\n",
    "    print((train_generator.classes).shape)\n",
    "    \n",
    "    train = train[:train_img_nums]\n",
    "    test = test[:test_img_nums]\n",
    "    \n",
    "    print(\"model %s\"%(model_name))\n",
    "    print(train.shape)\n",
    "    print(test.shape)\n",
    "    print((train_generator.classes).shape)\n",
    "    \n",
    "    print(train_generator.classes)\n",
    "    print(\"#\")\n",
    "\n",
    "    with h5py.File(\"gap_%s.h5\"%(model_name)) as h:\n",
    "        h.create_dataset(\"train\", data=train)\n",
    "        h.create_dataset(\"test\", data=test)\n",
    "        h.create_dataset(\"label\", data=train_generator.classes)\n",
    "\n",
    "# 输入所有的训练样本，后续在分割\n",
    "#write_gap(ResNet50, (224, 224), None,\n",
    "#          'ResNet50_finetune.h5', '../dataset/chest_xray/train-ready', '../dataset/chest_xray/test', 'ResNet50')\n",
    "write_gap(InceptionV3, (299, 299), inception_v3.preprocess_input, \n",
    "          'InceptionV3_finetune.h5', '../dataset/chest_xray/train-ready', '../dataset/chest_xray/test/', 'InceptionV3')\n",
    "write_gap(Xception, (299, 299), xception.preprocess_input, \n",
    "          'Xception_finetune.h5', '../dataset/chest_xray/train-ready', '../dataset/chest_xray/test', 'Xception')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 融合特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 4708, 2048)\n",
      "(2, 624, 2048)\n",
      "(4708, 4096)\n",
      "(624, 4096)\n",
      "[1 1 1 ... 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "np.random.seed(2017)\n",
    "\n",
    "X_train = []\n",
    "X_test = []\n",
    "\n",
    "# 特征是需要融合的，但label是一致的（没有使用乱序），即多个特征融合后对应同一个label\n",
    "\n",
    "#for filename in [\"gap_Xception.h5\", \"gap_InceptionV3.h5\", \"gap_ResNet50.h5\"]:\n",
    "for filename in [\"gap_Xception.h5\", \"gap_InceptionV3.h5\"]:\n",
    "    with h5py.File(filename, 'r') as h:\n",
    "        X_train.append(np.array(h['train']))\n",
    "        X_test.append(np.array(h['test']))\n",
    "        y_train = np.array(h['label'])\n",
    "        #X_train = np.array(h['train'])\n",
    "        #X_test = np.array(h['test'])\n",
    "        #y_train = np.array(h['label'])\n",
    "\n",
    "print(np.array(X_train).shape)\n",
    "print(np.array(X_test).shape)\n",
    "X_train = np.concatenate(X_train, axis=1)\n",
    "X_test = np.concatenate(X_test, axis=1)\n",
    "print(np.array(X_train).shape)\n",
    "print(np.array(X_test).shape)\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train)\n",
    "\n",
    "print(y_train)\n",
    "#print(\"fusion model\")\n",
    "#print(\"train.shape %d test.shape %d label.shape %d\"%(X_train.shape, X_test.shape, y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.]\n",
      "[0. 1.]\n",
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "y_train = K.one_hot(y_train, 2)\n",
    "y_train = K.eval(y_train)\n",
    "print(y_train[0])\n",
    "print(y_train[1])\n",
    "print(y_train[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 构建分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 8194      \n",
      "=================================================================\n",
      "Total params: 8,194\n",
      "Trainable params: 8,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "\n",
    "np.random.seed(2017)\n",
    "\n",
    "input_tensor = Input(X_train.shape[1:])\n",
    "#x = GlobalAveragePooling2D()(input_tensor)\n",
    "x = Dropout(0.5)(input_tensor)\n",
    "predictions = Dense(2, activation='softmax')(x)\n",
    "model = Model(input_tensor, predictions)\n",
    "\n",
    "model.compile(optimizer='adadelta', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 训练分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4472 samples, validate on 236 samples\n",
      "Epoch 1/10\n",
      "4472/4472 [==============================] - 5s 1ms/step - loss: 0.1271 - acc: 0.9644 - val_loss: 0.0331 - val_acc: 1.0000\n",
      "Epoch 2/10\n",
      "4472/4472 [==============================] - 0s 60us/step - loss: 0.0229 - acc: 1.0000 - val_loss: 0.0144 - val_acc: 1.0000\n",
      "Epoch 3/10\n",
      "4472/4472 [==============================] - 0s 58us/step - loss: 0.0112 - acc: 1.0000 - val_loss: 0.0074 - val_acc: 1.0000\n",
      "Epoch 4/10\n",
      "4472/4472 [==============================] - 0s 58us/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 5/10\n",
      "4472/4472 [==============================] - 0s 54us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 6/10\n",
      "4472/4472 [==============================] - 0s 60us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 7/10\n",
      "4472/4472 [==============================] - 0s 53us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 8.7954e-04 - val_acc: 1.0000\n",
      "Epoch 8/10\n",
      "4472/4472 [==============================] - 0s 53us/step - loss: 9.8752e-04 - acc: 1.0000 - val_loss: 6.4387e-04 - val_acc: 1.0000\n",
      "Epoch 9/10\n",
      "4472/4472 [==============================] - 0s 55us/step - loss: 7.8758e-04 - acc: 1.0000 - val_loss: 5.0326e-04 - val_acc: 1.0000\n",
      "Epoch 10/10\n",
      "4472/4472 [==============================] - 0s 49us/step - loss: 7.0996e-04 - acc: 1.0000 - val_loss: 4.1132e-04 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c615632080>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 10\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 预测测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "794/794 [==============================] - 2s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "test_predictions = model.predict(X_test, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 写入CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.0267883e-11 1.0625736e-07 6.8008569e-07 9.9999797e-01 3.8216777e-13\n",
      " 6.9565328e-07 2.9235672e-09 1.4573551e-07 1.7710824e-10 6.6497705e-08\n",
      " 8.1254939e-08 8.0354567e-08]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(test_predictions[3])\n",
    "print(np.argmax(test_predictions[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 794 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "import csv  \n",
    "\n",
    "def as_num(x):\n",
    "    y = '{:.6f}'.format(x) # 6f表示保留6位小数点的float型\n",
    "    return(y)\n",
    "\n",
    "class_index = ['Black-grass', 'Charlock', \n",
    "               'Cleavers', 'Common Chickweed', \n",
    "               'Common wheat', 'Fat Hen', \n",
    "               'Loose Silky-bent', 'Maize', \n",
    "               'Scentless Mayweed', 'Shepherds Purse', \n",
    "               'Small-flowered Cranesbill', 'Sugar beet']\n",
    "\n",
    "gen = ImageDataGenerator()\n",
    "test_generator = gen.flow_from_directory(\"../dataset/test/\", (224, 224), shuffle=False, \n",
    "                                         batch_size=16, class_mode=None)\n",
    "\n",
    "with open('output.csv', 'w+', newline='') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow([\"file\", \"species\"])\n",
    "    for index, fname in enumerate(test_generator.filenames):\n",
    "        fname = fname.split(\"\\\\\")[1]\n",
    "        class_name = class_index[np.argmax(test_predictions[index])]\n",
    "        writer.writerow([fname, class_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
